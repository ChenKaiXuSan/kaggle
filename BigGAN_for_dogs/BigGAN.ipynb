{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import autograd\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "# from albumentations.pytorch import ToTensor\n",
    "\n",
    "import glob\n",
    "import xml.etree.ElementTree as ET \n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import os \n",
    "print(os.listdir('../data/generative-dog-images'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['all-dogs.zip', 'Annotation.zip', 'all-dogs', 'Annotation']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "TIME_LIMIT = 32400 - 60 * 10\n",
    "start_time = time.time()\n",
    "\n",
    "def elapsed_time(start_time):\n",
    "    return time.time() - start_time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# random seeds\n",
    "seed = 2019\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 4\n",
    "EMA = False\n",
    "LABEL_NOISE = False\n",
    "LABEL_NOISE_PROB = 0.1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-Processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "PATH = '../data/generative-dog-images/all-dogs/all-dogs'\n",
    "img_filnames = os.listdir(PATH)\n",
    "len(img_filnames)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20579"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "PATH_ANNOTATION = '../data/generative-dog-images/Annotation/Annotation/'\n",
    "breeds = glob.glob(PATH_ANNOTATION + '*')\n",
    "annotations = []\n",
    "for breed in breeds:\n",
    "    annotations += glob.glob(breed + '/*')\n",
    "len(annotations)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20580"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "breed_map = {}\n",
    "for annotation in annotations:\n",
    "    breed = annotation.split('/')[-2]\n",
    "    index = breed.split('-')[0]\n",
    "    breed_map.setdefault(index, breed)\n",
    "\n",
    "n_classes = len(breed_map)\n",
    "n_classes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "breed_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'n02092002': 'n02092002-Scottish_deerhound',\n",
       " 'n02099849': 'n02099849-Chesapeake_Bay_retriever',\n",
       " 'n02091244': 'n02091244-Ibizan_hound',\n",
       " 'n02095314': 'n02095314-wire-haired_fox_terrier',\n",
       " 'n02091831': 'n02091831-Saluki',\n",
       " 'n02102318': 'n02102318-cocker_spaniel',\n",
       " 'n02104365': 'n02104365-schipperke',\n",
       " 'n02090622': 'n02090622-borzoi',\n",
       " 'n02113023': 'n02113023-Pembroke',\n",
       " 'n02105505': 'n02105505-komondor',\n",
       " 'n02099601': 'n02099601-golden_retriever',\n",
       " 'n02085782': 'n02085782-Japanese_spaniel',\n",
       " 'n02110063': 'n02110063-malamute',\n",
       " 'n02086079': 'n02086079-Pekinese',\n",
       " 'n02097130': 'n02097130-giant_schnauzer',\n",
       " 'n02107142': 'n02107142-Doberman',\n",
       " 'n02097209': 'n02097209-standard_schnauzer',\n",
       " 'n02106662': 'n02106662-German_shepherd',\n",
       " 'n02093754': 'n02093754-Border_terrier',\n",
       " 'n02105251': 'n02105251-briard',\n",
       " 'n02108551': 'n02108551-Tibetan_mastiff',\n",
       " 'n02108422': 'n02108422-bull_mastiff',\n",
       " 'n02093859': 'n02093859-Kerry_blue_terrier',\n",
       " 'n02104029': 'n02104029-kuvasz',\n",
       " 'n02107574': 'n02107574-Greater_Swiss_Mountain_dog',\n",
       " 'n02095570': 'n02095570-Lakeland_terrier',\n",
       " 'n02106166': 'n02106166-Border_collie',\n",
       " 'n02090379': 'n02090379-redbone',\n",
       " 'n02113712': 'n02113712-miniature_poodle',\n",
       " 'n02113186': 'n02113186-Cardigan',\n",
       " 'n02108000': 'n02108000-EntleBucher',\n",
       " 'n02091467': 'n02091467-Norwegian_elkhound',\n",
       " 'n02100236': 'n02100236-German_short-haired_pointer',\n",
       " 'n02107683': 'n02107683-Bernese_mountain_dog',\n",
       " 'n02086910': 'n02086910-papillon',\n",
       " 'n02097474': 'n02097474-Tibetan_terrier',\n",
       " 'n02093428': 'n02093428-American_Staffordshire_terrier',\n",
       " 'n02092339': 'n02092339-Weimaraner',\n",
       " 'n02108089': 'n02108089-boxer',\n",
       " 'n02105641': 'n02105641-Old_English_sheepdog',\n",
       " 'n02110958': 'n02110958-pug',\n",
       " 'n02087394': 'n02087394-Rhodesian_ridgeback',\n",
       " 'n02097298': 'n02097298-Scotch_terrier',\n",
       " 'n02099267': 'n02099267-flat-coated_retriever',\n",
       " 'n02099712': 'n02099712-Labrador_retriever',\n",
       " 'n02096177': 'n02096177-cairn',\n",
       " 'n02111277': 'n02111277-Newfoundland',\n",
       " 'n02089867': 'n02089867-Walker_hound',\n",
       " 'n02098413': 'n02098413-Lhasa',\n",
       " 'n02088364': 'n02088364-beagle',\n",
       " 'n02111889': 'n02111889-Samoyed',\n",
       " 'n02096051': 'n02096051-Airedale',\n",
       " 'n02088466': 'n02088466-bloodhound',\n",
       " 'n02093647': 'n02093647-Bedlington_terrier',\n",
       " 'n02101556': 'n02101556-clumber',\n",
       " 'n02113624': 'n02113624-toy_poodle',\n",
       " 'n02111500': 'n02111500-Great_Pyrenees',\n",
       " 'n02115641': 'n02115641-dingo',\n",
       " 'n02102040': 'n02102040-English_springer',\n",
       " 'n02088094': 'n02088094-Afghan_hound',\n",
       " 'n02101388': 'n02101388-Brittany_spaniel',\n",
       " 'n02096585': 'n02096585-Boston_bull',\n",
       " 'n02099429': 'n02099429-curly-coated_retriever',\n",
       " 'n02102973': 'n02102973-Irish_water_spaniel',\n",
       " 'n02112706': 'n02112706-Brabancon_griffon',\n",
       " 'n02105056': 'n02105056-groenendael',\n",
       " 'n02111129': 'n02111129-Leonberg',\n",
       " 'n02097658': 'n02097658-silky_terrier',\n",
       " 'n02093256': 'n02093256-Staffordshire_bullterrier',\n",
       " 'n02113799': 'n02113799-standard_poodle',\n",
       " 'n02109961': 'n02109961-Eskimo_dog',\n",
       " 'n02089973': 'n02089973-English_foxhound',\n",
       " 'n02095889': 'n02095889-Sealyham_terrier',\n",
       " 'n02097047': 'n02097047-miniature_schnauzer',\n",
       " 'n02105162': 'n02105162-malinois',\n",
       " 'n02113978': 'n02113978-Mexican_hairless',\n",
       " 'n02115913': 'n02115913-dhole',\n",
       " 'n02106382': 'n02106382-Bouvier_des_Flandres',\n",
       " 'n02110185': 'n02110185-Siberian_husky',\n",
       " 'n02094258': 'n02094258-Norwich_terrier',\n",
       " 'n02093991': 'n02093991-Irish_terrier',\n",
       " 'n02094114': 'n02094114-Norfolk_terrier',\n",
       " 'n02109525': 'n02109525-Saint_Bernard',\n",
       " 'n02085936': 'n02085936-Maltese_dog',\n",
       " 'n02086646': 'n02086646-Blenheim_spaniel',\n",
       " 'n02088238': 'n02088238-basset',\n",
       " 'n02098286': 'n02098286-West_Highland_white_terrier',\n",
       " 'n02085620': 'n02085620-Chihuahua',\n",
       " 'n02090721': 'n02090721-Irish_wolfhound',\n",
       " 'n02088632': 'n02088632-bluetick',\n",
       " 'n02101006': 'n02101006-Gordon_setter',\n",
       " 'n02100583': 'n02100583-vizsla',\n",
       " 'n02105412': 'n02105412-kelpie',\n",
       " 'n02107312': 'n02107312-miniature_pinscher',\n",
       " 'n02112137': 'n02112137-chow',\n",
       " 'n02086240': 'n02086240-Shih-Tzu',\n",
       " 'n02110627': 'n02110627-affenpinscher',\n",
       " 'n02091134': 'n02091134-whippet',\n",
       " 'n02102480': 'n02102480-Sussex_spaniel',\n",
       " 'n02091635': 'n02091635-otterhound',\n",
       " 'n02100735': 'n02100735-English_setter',\n",
       " 'n02091032': 'n02091032-Italian_greyhound',\n",
       " 'n02106030': 'n02106030-collie',\n",
       " 'n02106550': 'n02106550-Rottweiler',\n",
       " 'n02096294': 'n02096294-Australian_terrier',\n",
       " 'n02087046': 'n02087046-toy_terrier',\n",
       " 'n02105855': 'n02105855-Shetland_sheepdog',\n",
       " 'n02116738': 'n02116738-African_hunting_dog',\n",
       " 'n02109047': 'n02109047-Great_Dane',\n",
       " 'n02100877': 'n02100877-Irish_setter',\n",
       " 'n02112350': 'n02112350-keeshond',\n",
       " 'n02096437': 'n02096437-Dandie_Dinmont',\n",
       " 'n02110806': 'n02110806-basenji',\n",
       " 'n02107908': 'n02107908-Appenzeller',\n",
       " 'n02102177': 'n02102177-Welsh_springer_spaniel',\n",
       " 'n02098105': 'n02098105-soft-coated_wheaten_terrier',\n",
       " 'n02108915': 'n02108915-French_bulldog',\n",
       " 'n02112018': 'n02112018-Pomeranian',\n",
       " 'n02094433': 'n02094433-Yorkshire_terrier',\n",
       " 'n02089078': 'n02089078-black-and-tan_coonhound'}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# crop images using bounding box \n",
    "def bounding_box(img):\n",
    "    bpath = PATH_ANNOTATION + str(breed_map[img.split('_')[0]]) + '/' + str(img.split('.')[0])\n",
    "    tree = ET.parse(bpath)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "    bbxs = []\n",
    "    for o in objects:\n",
    "        bndbox = o.find('bndbox') # reading bound box \n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        bbxs.append((xmin, ymin, xmax, ymax))\n",
    "    return bbxs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def bounding_box_ratio(img):\n",
    "    bpath = PATH_ANNOTATION + str(breed_map[img.split('_')[0]]) + '/' + str(img.split('.')[0])\n",
    "    tree = ET.parse(bpath)\n",
    "    root = tree.getroot()\n",
    "    objects = root.findall('object')\n",
    "    bbx_ratios = []\n",
    "    for o in objects:\n",
    "        bndbox = o.find('bndbox') # reading bound box \n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        xlen = xmax - xmin\n",
    "        ylen = ymax - ymin\n",
    "        ratio = ylen / xlen\n",
    "\n",
    "        bbx_ratios.append((xlen, ylen, ratio))\n",
    "    \n",
    "    return bbx_ratios"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%%time\n",
    "# threshold for aspect ratio, at the same time idx for each bbx \n",
    "img_filnames_th = []\n",
    "ratios_th = []\n",
    "for img in tqdm(img_filnames):\n",
    "    bbx_ratios = bounding_box_ratio(img)\n",
    "    for i, (xlen, ylen, ratio) in enumerate(bbx_ratios):\n",
    "        if ((ratio>0.2) & (ratio<4.0)):\n",
    "            img_filnames_th.append(img[:-4] + '_' + str(i) + '.jpg')\n",
    "            ratios_th.append(ratio)\n",
    "\n",
    "ratios_th = np.array(ratios_th)\n",
    "\n",
    "print('original:', len(img_filnames))\n",
    "print('after th:', len(img_filnames_th))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20579/20579 [00:12<00:00, 1711.03it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "original: 20579\n",
      "after th: 22119\n",
      "CPU times: user 663 ms, sys: 302 ms, total: 965 ms\n",
      "Wall time: 12 s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "intruders = [\n",
    "    #n02088238-basset\n",
    "    'n02088238_10870_0.jpg',\n",
    "    \n",
    "    #n02088466-bloodhound\n",
    "    'n02088466_6901_1.jpg',\n",
    "    'n02088466_6963_0.jpg',\n",
    "    'n02088466_9167_0.jpg',\n",
    "    'n02088466_9167_1.jpg',\n",
    "    'n02088466_9167_2.jpg',\n",
    "    \n",
    "    #n02089867-Walker_hound\n",
    "    'n02089867_2221_0.jpg',\n",
    "    'n02089867_2227_1.jpg',\n",
    "    \n",
    "    #n02089973-English_foxhound # No details\n",
    "    'n02089973_1132_3.jpg',\n",
    "    'n02089973_1352_3.jpg',\n",
    "    'n02089973_1458_1.jpg',\n",
    "    'n02089973_1799_2.jpg',\n",
    "    'n02089973_2791_3.jpg',\n",
    "    'n02089973_4055_0.jpg',\n",
    "    'n02089973_4185_1.jpg',\n",
    "    'n02089973_4185_2.jpg',\n",
    "    \n",
    "    #n02090379-redbone\n",
    "    'n02090379_4673_1.jpg',\n",
    "    'n02090379_4875_1.jpg',\n",
    "    \n",
    "    #n02090622-borzoi # Confusing\n",
    "    'n02090622_7705_1.jpg',\n",
    "    'n02090622_9358_1.jpg',\n",
    "    'n02090622_9883_1.jpg',\n",
    "    \n",
    "    #n02090721-Irish_wolfhound # very small\n",
    "    'n02090721_209_1.jpg',\n",
    "    'n02090721_1222_1.jpg',\n",
    "    'n02090721_1534_1.jpg',\n",
    "    'n02090721_1835_1.jpg',\n",
    "    'n02090721_3999_1.jpg',\n",
    "    'n02090721_4089_1.jpg',\n",
    "    'n02090721_4276_2.jpg',\n",
    "    \n",
    "    #n02091032-Italian_greyhound\n",
    "    'n02091032_722_1.jpg',\n",
    "    'n02091032_745_1.jpg',\n",
    "    'n02091032_1773_0.jpg',\n",
    "    'n02091032_9592_0.jpg',\n",
    "    \n",
    "    #n02091134-whippet\n",
    "    'n02091134_2349_1.jpg',\n",
    "    'n02091134_14246_2.jpg',\n",
    "    \n",
    "    #n02091244-Ibizan_hound\n",
    "    'n02091244_583_1.jpg',\n",
    "    'n02091244_2407_0.jpg',\n",
    "    'n02091244_3438_1.jpg',\n",
    "    'n02091244_5639_1.jpg',\n",
    "    'n02091244_5639_2.jpg',\n",
    "    \n",
    "    #n02091467-Norwegian_elkhound\n",
    "    'n02091467_473_0.jpg',\n",
    "    'n02091467_4386_1.jpg',\n",
    "    'n02091467_4427_1.jpg',\n",
    "    'n02091467_4558_1.jpg',\n",
    "    'n02091467_4560_1.jpg',\n",
    "    \n",
    "    #n02091635-otterhound\n",
    "    'n02091635_1192_1.jpg',\n",
    "    'n02091635_4422_0.jpg',\n",
    "    \n",
    "    #n02091831-Saluki\n",
    "    'n02091831_1594_1.jpg',\n",
    "    'n02091831_2880_0.jpg',\n",
    "    'n02091831_7237_1.jpg',\n",
    "    \n",
    "    #n02092002-Scottish_deerhound\n",
    "    'n02092002_1551_1.jpg',\n",
    "    'n02092002_1937_1.jpg',\n",
    "    'n02092002_4218_0.jpg',\n",
    "    'n02092002_4596_0.jpg',\n",
    "    'n02092002_5246_1.jpg',\n",
    "    'n02092002_6518_0.jpg',\n",
    "    \n",
    "    #02093256-Staffordshire_bullterrier\n",
    "    'n02093256_1826_1.jpg',\n",
    "    'n02093256_4997_0.jpg',\n",
    "    'n02093256_14914_0.jpg',\n",
    "    \n",
    "    #n02093428-American_Staffordshire_terrier\n",
    "    'n02093428_5662_0.jpg',\n",
    "    'n02093428_6949_1.jpg'\n",
    "            ]\n",
    "\n",
    "len(intruders)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def data_preprocessing(img_path, bbx_idx):\n",
    "    bbx = bounding_box(img_path)[bbx_idx]\n",
    "    img = Image.open(os.path.join(PATH, img_path)) # PILImage format\n",
    "    img_cropped = img.crop(bbx)\n",
    "    return img_cropped"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%%time \n",
    "breed_map_2 = {}\n",
    "for i, b in enumerate(breed_map.keys()):\n",
    "    breed_map_2[b] = i"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12 µs, sys: 3 µs, total: 15 µs\n",
      "Wall time: 16.5 µs\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "class DogDataset(Dataset):\n",
    "    def __init__(self, path, img_list, transform1=None, transform2=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.path = path\n",
    "        self.img_list = img_list\n",
    "        self.transform1 = transform1\n",
    "        self.transform2 = transform2\n",
    "\n",
    "        self.imgs = [] \n",
    "        self.labels = []\n",
    "        for i, full_img_path in enumerate(self.img_list):\n",
    "            if full_img_path in intruders:\n",
    "                continue\n",
    "            \n",
    "            # img \n",
    "            img_path = full_img_path[:-6] + '.jpg'\n",
    "            bbx_idx = int(full_img_path[-5])\n",
    "            img = data_preprocessing(img_path, bbx_idx)\n",
    "            if self.transform1:\n",
    "                img = self.transform1(img) # output shape=(c, h, h, w)\n",
    "            self.imgs.append(img)\n",
    "\n",
    "            # label \n",
    "            label = breed_map_2[img_path.split('_')[0]]\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "        if self.transform2:\n",
    "            img = self.transform2(img)\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {'img':img, 'label':label}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "%%time \n",
    "# generate 64x64 images!\n",
    "img_size = 64\n",
    "batch_size = BATCH_SIZE\n",
    "MEAN1, MEAN2, MEAN3 = 0.5, 0.5, 0.5\n",
    "STD1, STD2, STD3 = 0.5, 0.5, 0.5\n",
    "\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.Resize(img_size)\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.RandomCrop(img_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[MEAN1, MEAN2, MEAN3], std=[STD1, STD2, STD3])\n",
    "])\n",
    "\n",
    "train_set =  DogDataset(\n",
    "    path=PATH,\n",
    "    img_list=img_filnames_th,\n",
    "    transform1=transform1,\n",
    "    transform2=transform2,\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_set, \n",
    "    shuffle=True, batch_size=batch_size,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 49 s, sys: 886 ms, total: 49.9 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "len(train_set)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22059"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "img = data_preprocessing(img_filnames_th[1500][:-6] + '.jpg', 0)\n",
    "img = transform1(img)\n",
    "img "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x76 at 0x7F33141E9390>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Device"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def conv3x3(in_channels, out_channels): # not change resolusion\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, dilation=1, bias=False)\n",
    "\n",
    "def conv1x1(in_channels, out_channels): # not change resolusion \n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False)\n",
    "\n",
    "def init_weight(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.orthogonal_(m.weight, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    \n",
    "    elif classname.find('Batch') != -1:\n",
    "        m.weight.data.normal_(1, 0.02)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.orthogonal_(m.weight, gain=1)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "    elif classname.find('Embedding') != -1:\n",
    "        nn.init.orthogonal_(m.weight, gain=1)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.theta = nn.utils.spectral_norm(conv1x1(channels, channels // 8)).apply(init_weight)\n",
    "        self.phi = nn.utils.spectral_norm(conv1x1(channels, channels // 8)).apply(init_weight)\n",
    "\n",
    "        self.g = nn.utils.spectral_norm(conv1x1(channels, channels // 2)).apply(init_weight)\n",
    "        self.o = nn.utils.spectral_norm(conv1x1(channels // 2, channels)).apply(init_weight)\n",
    "\n",
    "        self.gamma = nn.Parameter(torch.tensor(0.), requires_grad=True)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch, c, h, w = inputs.size()\n",
    "\n",
    "        theta = self.theta(inputs) # (*, c/8, h, w)\n",
    "        phi = F.max_pool2d(self.phi(inputs), [2, 2]) # (*, c/8, h/2, w/2)\n",
    "        g = F.max_pool2d(self.g(inputs), [2, 2]) # (*, c/2, h/2, w/2)\n",
    "\n",
    "        theta = theta.view(batch, self.channels // 8, -1) # (*, c/8, h*w)\n",
    "        phi = phi.view(batch, self.channels // 8, -1) # (*, c/8, h*w/4)\n",
    "        g = g.view(batch, self.channels // 2, -1) # (*, c/2, h*w/4)\n",
    "\n",
    "        beta = F.softmax(torch.bmm(theta.transpose(1, 2), phi), -1) # (*, h*w, h*w/4)\n",
    "        o = self.o(torch.bmm(g, beta.transpose(1, 2)).view(batch, self.channels//2, h, w)) # (*, c, h, w)\n",
    "\n",
    "        return self.gamma * o + inputs\n",
    "\n",
    "class ConditionalNorm(nn.Module):\n",
    "    def __init__(self, in_channel, n_condition):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channel, affine=False) # no learning parameters\n",
    "        self.embed = nn.Linear(n_condition, in_channel * 2)\n",
    "\n",
    "        nn.init.orthogonal_(self.embed.weight.data[:, :in_channel], gain=1)\n",
    "        self.embed.weight.data[:, in_channel:].zero_()\n",
    "\n",
    "    def forward(self, inputs, label):\n",
    "        out = self.bn(inputs)\n",
    "        embed = self.embed(label.float())\n",
    "        gamma, beta = embed.chunk(2, dim=1)\n",
    "        gamma = gamma.unsqueeze(2).unsqueeze(3)\n",
    "        beta = beta.unsqueeze(2).unsqueeze(3)\n",
    "        out = gamma * out + beta\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# BigGAN + leaky_relu\n",
    "class ResBlock_G(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, condition_dim, upsample=True):\n",
    "        super().__init__()\n",
    "        self.cbn1 = ConditionalNorm(in_channel, condition_dim)\n",
    "        self.upsample = nn.Sequential()\n",
    "        if upsample:\n",
    "            self.upsample.add_module('upsample', nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "\n",
    "        self.conv3x3_1 = nn.utils.spectral_norm(conv3x3(in_channel, out_channel)).apply(init_weight)\n",
    "        self.cbn2 = ConditionalNorm(out_channel, condition_dim)\n",
    "        self.conv3x3_2 = nn.utils.spectral_norm(conv3x3(out_channel, out_channel)).apply(init_weight)\n",
    "        self.conv1x1 = nn.utils.spectral_norm(conv1x1(in_channel, out_channel)).apply(init_weight)\n",
    "\n",
    "    def forward(self, inputs, condition):\n",
    "        x = F.leaky_relu(self.cbn1(inputs, condition))\n",
    "        x = self.upsample(x)\n",
    "        x = self.conv3x3_1(x)\n",
    "        x = self.conv3x3_2(F.leaky_relu(self.cbn2(x, condition)))\n",
    "        x += self.conv1x1(self.upsample(inputs)) # shortcut\n",
    "        return x \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_feat, codes_dim=24, n_classes=n_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.utils.spectral_norm(nn.Linear(codes_dim, 16*n_feat*4*4)).apply(init_weight)\n",
    "        )\n",
    "        self.res1 = ResBlock_G(16*n_feat, 16*n_feat, codes_dim+n_classes, upsample=True)\n",
    "        self.res2 = ResBlock_G(16*n_feat, 8*n_feat, codes_dim+n_classes, upsample=True)\n",
    "        self.res3 = ResBlock_G(8*n_feat, 4*n_feat, codes_dim+n_classes, upsample=True)\n",
    "        \n",
    "        self.attn = Attention(4*n_feat)\n",
    "\n",
    "        self.res4 = ResBlock_G(4*n_feat, 2*n_feat, codes_dim+n_classes, upsample=True)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.utils.spectral_norm(conv3x3(2*n_feat, 3)).apply(init_weight)\n",
    "        )\n",
    "\n",
    "    def forward(self, z, label_ohe, codes_dim=24):\n",
    "        '''\n",
    "        z.shape = (*, 120)\n",
    "        label_ohe.shape = (*, n_classes)\n",
    "\n",
    "        Args:\n",
    "            z ([type]): [description]\n",
    "            label_ohe ([type]): [description]\n",
    "            codes_dim (int, optional): [description]. Defaults to 24.\n",
    "        '''\n",
    "        batch = z.size(0)\n",
    "        z = z.squeeze()\n",
    "        label_ohe = label_ohe.squeeze()\n",
    "        codes = torch.split(z, codes_dim, dim=1)\n",
    "\n",
    "        x = self.fc(codes[0]) # (*, 16ch*4*4)\n",
    "        x = x.view(batch, -1, 4, 4) # (*, 16ch, 4, 4)\n",
    "\n",
    "        condition = torch.cat([codes[1], label_ohe], dim=1) # (codes_dim+n_classes)\n",
    "        x = self.res1(x, condition) # (*, 16ch, 8, 8)\n",
    "\n",
    "        condition = torch.cat([codes[2], label_ohe], dim=1)\n",
    "        x = self.res2(x, condition) # (*, 8ch, 16, 16)\n",
    "\n",
    "        condition = torch.cat([codes[3], label_ohe], dim=1)\n",
    "        x = self.res3(x, condition) # (*, 4ch, 32, 32)\n",
    "        x = self.attn(x) # not change shape\n",
    "\n",
    "        condition = torch.cat([codes[4], label_ohe], dim=1)\n",
    "        x = self.res4(x, condition) # (*, 2ch, 64, 64)\n",
    "        \n",
    "        x = self.conv(x) # (*, 3, 64, 64)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "class ResBlock_D(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, downsample=True):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.utils.spectral_norm(conv3x3(in_channel, out_channel)).apply(init_weight),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.utils.spectral_norm(conv3x3(out_channel, out_channel)).apply(init_weight)\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential(\n",
    "            nn.utils.spectral_norm(conv1x1(in_channel, out_channel)).apply(init_weight)\n",
    "        )\n",
    "        \n",
    "        if downsample:\n",
    "            self.layer.add_module('avgpool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "            self.shortcut.add_module('avgpool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.layer(inputs)\n",
    "        x += self.shortcut(inputs)\n",
    "        return x \n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_feat, n_classes=n_classes):\n",
    "        super().__init__()\n",
    "        self.res1 = ResBlock_D(3, n_feat, downsample=True)\n",
    "        self.attn = Attention(n_feat)\n",
    "        self.res2 = ResBlock_D(n_feat, 2*n_feat, downsample=True)\n",
    "        self.res3 = ResBlock_D(2*n_feat, 4*n_feat, downsample=True)\n",
    "        self.res4 = ResBlock_D(4*n_feat, 8*n_feat, downsample=True)\n",
    "        self.res5 = ResBlock_D(8*n_feat, 16*n_feat, downsample=False)\n",
    "\n",
    "        self.fc = nn.utils.spectral_norm(nn.Linear(16*n_feat, 1)).apply(init_weight)\n",
    "        self.embedding = nn.Embedding(num_embeddings=n_classes, embedding_dim=16*n_feat).apply(init_weight)\n",
    "\n",
    "    def forward(self, inputs, label):\n",
    "        batch = inputs.size(0) # (*, 3, 64, 64)\n",
    "        h = self.res1(inputs) # (*, ch, 32, 32)\n",
    "        h = self.attn(h) # not change shape\n",
    "        h = self.res2(h) # (*, 2ch, 16, 16)\n",
    "        h = self.res3(h) # (*, 4ch, 8, 8)\n",
    "        h = self.res4(h) # (*, 8ch, 4, 4)\n",
    "        h = self.res5(h) # (*, 16ch, 4, 4)\n",
    "        h = torch.sum((F.leaky_relu(h, 0.2)).view(batch, -1, 4*4), dim=2) # GlobalSumPool (*, 16ch)\n",
    "\n",
    "        outputs = self.fc(h) # (*, 1)\n",
    "\n",
    "        if label is not None:\n",
    "            embed = self.embedding(label) # (*, 16ch)\n",
    "            outputs += torch.sum(embed*h, dim=1, keepdim=True) # (*, 1)\n",
    "\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        return outputs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# BigGAN\n",
    "print(count_parameters(model=Generator(n_feat=27, codes_dim=24, n_classes=n_classes))) # z.shape = (*, 120)\n",
    "print(count_parameters(model=Discriminator(n_feat=33, n_classes=n_classes)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6089851\n",
      "5259641\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def generate_img(netG, fixed_noise, fixed_aux_labels=None):\n",
    "    if fixed_aux_labels is not None:\n",
    "        gen_image = netG(fixed_noise, fixed_aux_labels).to('cpu').clone().detach().squeeze(0)\n",
    "    else:\n",
    "        gen_image = netG(fixed_noise).to('cpu').clone().detach().squeeze(0)\n",
    "\n",
    "    # denormalize \n",
    "    gen_image = gen_image * 0.5 + 0.5\n",
    "    gen_image_numpy = gen_image.numpy().transpose(0, 2, 3, 1)\n",
    "    return gen_image_numpy\n",
    "\n",
    "def show_generate_imgs(netG, fixed_noise, fixed_aux_labels=None):\n",
    "    gen_images_numpy = generate_img(netG, fixed_noise, fixed_aux_labels)\n",
    "\n",
    "    fig = plt.figure(figsize=(25,16))\n",
    "    # display 10 images from each class \n",
    "    for i, img in enumerate(gen_images_numpy):\n",
    "        ax = fig.add_subplot(4, 8, i+1, xticks=[], yticks=[])\n",
    "        plt.imshow(img)\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# BigGAN\n",
    "def run(lr_G = 3e-4, lr_D = 3e-4, beta1 = 0.0, beta2 = 0.999, nz=120, epochs=2, n_ite_D=1, ema_decay_rate=0.999, show_epoch_list=None, output_freq = 10):\n",
    "    netG = Generator(n_feat=36, codes_dim=24, n_classes=n_classes).to(device) # z.shape=(*, 120)\n",
    "    netD = Discriminator(n_feat=42, n_classes=n_classes).to(device)\n",
    "\n",
    "    if EMA:\n",
    "        # EMA of G for sampling \n",
    "        netG_EMA = Generator(n_feat=42, codes_dim=24, n_classes=n_classes).to(device)\n",
    "        netG_EMA.load_state_dict(netG.state_dict())\n",
    "        for p in netG_EMA.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    print(count_parameters(netG))\n",
    "    print(count_parameters(netD))\n",
    "\n",
    "    real_label = 0.9\n",
    "    fake_label = 0\n",
    "\n",
    "    D_loss_list = []\n",
    "    G_loss_list = []\n",
    "\n",
    "    dis_criterion = nn.BCELoss().to(device)\n",
    "\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=lr_D, betas=(beta1, beta2))\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=lr_G, betas=(beta1, beta2))\n",
    "\n",
    "    fixed_noise = torch.randn(32, nz, 1, 1, device=device)\n",
    "\n",
    "    fixed_aux_labels = np.random.randint(0, n_classes, 32)\n",
    "    fixed_aux_labels_ohe = np.eye(n_classes)[fixed_aux_labels]\n",
    "    fixed_aux_labels_ohe = torch.from_numpy(fixed_aux_labels_ohe[:, :, np.newaxis, np.newaxis])\n",
    "    fixed_aux_labels_ohe = fixed_aux_labels_ohe.float().to(device, non_blocking=True)\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    # training here \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if elapsed_time(start_time) > TIME_LIMIT:\n",
    "            print(f'elapsed_time go beyond {TIME_LIMIT} sec')\n",
    "            break\n",
    "        D_running_loss = 0\n",
    "        G_running_loss = 0\n",
    "        \n",
    "        for ii, data in enumerate(train_loader):\n",
    "            # update D network \n",
    "            for _ in range(n_ite_D):\n",
    "\n",
    "                if LABEL_NOISE:\n",
    "                    real_label = 0.9\n",
    "                    fake_label = 0\n",
    "                    if np.random.random() < LABEL_NOISE_PROB:\n",
    "                        real_label = 0\n",
    "                        fake_label = 0.9\n",
    "\n",
    "                # train with real \n",
    "                netD.zero_grad()\n",
    "                real_images = data['img'].to(device, non_blocking=True)\n",
    "                batch_size = real_images.size(0)\n",
    "                dis_labels = torch.full((batch_size, 1), real_label, device=device) # (*, )\n",
    "                aux_labels = data['label'].long().to(device, non_blocking=True) # (*, )\n",
    "                dis_output = netD(real_images, aux_labels) # dis shape (*, 1)\n",
    "\n",
    "                errD_real = dis_criterion(dis_output, dis_labels)\n",
    "                errD_real.backward(retain_graph=True)\n",
    "\n",
    "                # train with fake \n",
    "                noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "\n",
    "                aux_labels = np.random.randint(0, n_classes, batch_size)\n",
    "                aux_labels_ohe = np.eye(n_classes)[aux_labels]\n",
    "                aux_labels_ohe = torch.from_numpy(aux_labels_ohe[:, :, np.newaxis, np.newaxis])\n",
    "                aux_labels_ohe = aux_labels_ohe.float().to(device=device, non_blocking=True)\n",
    "\n",
    "                aux_labels = torch.from_numpy(aux_labels).long().to(device=device, non_blocking=True)\n",
    "\n",
    "                fake = netG(noise, aux_labels_ohe) # (*, 3, 64,64)\n",
    "\n",
    "                dis_labels.fill_(fake_label)\n",
    "                dis_output = netD(fake.detach(), aux_labels)\n",
    "                \n",
    "                errD_fake = dis_criterion(dis_output, dis_labels)\n",
    "                errD_fake.backward(retain_graph=True)\n",
    "\n",
    "                D_running_loss += (errD_real.item() + errD_fake.item()) / len(train_loader)\n",
    "                optimizerD.step()\n",
    "\n",
    "            # update G network\n",
    "            netG.zero_grad()\n",
    "            dis_labels.fill_(real_label) # fake labels are real for generator cost \n",
    "            noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "\n",
    "            aux_labels = np.random.randint(0, n_classes, batch_size)\n",
    "            aux_labels_ohe = np.eye(n_classes)[aux_labels]\n",
    "            aux_labels_ohe = torch.from_numpy(aux_labels_ohe[:, :, np.newaxis, np.newaxis])\n",
    "            aux_labels_ohe = aux_labels_ohe.float().to(device, non_blocking=True)\n",
    "            \n",
    "            aux_labels = torch.from_numpy(aux_labels).long().to(device, non_blocking=True)\n",
    "\n",
    "            fake = netG(noise, aux_labels_ohe)\n",
    "\n",
    "            dis_output = netD(fake, aux_labels)\n",
    "            errG = dis_criterion(dis_output, dis_labels)\n",
    "            errG.backward(retain_graph=True)\n",
    "            \n",
    "            G_running_loss += errG.item() / len(train_loader)\n",
    "            optimizerG.step()\n",
    "\n",
    "        if EMA:\n",
    "            # update netG_EMA\n",
    "            param_itr = cycle(netG.parameters())\n",
    "            for i, p_EMA in enumerate(netG_EMA.parameters()):\n",
    "                p = next(param_itr)\n",
    "                p_EMA.data = (1-ema_decay_rate) * p_EMA.data + ema_decay_rate * p.data\n",
    "                p_EMA.requires_grad = False\n",
    "\n",
    "        # log \n",
    "        D_loss_list.append(D_running_loss)\n",
    "        G_loss_list.append(G_running_loss)\n",
    "\n",
    "        # output \n",
    "        if epoch % output_freq == 0:\n",
    "            print('[{:d}/{:d}] D_loss = {:.3f}, G_loss = {:.3f}, elapsed_time = {:.1f} min'.format(epoch,epochs,D_running_loss,G_running_loss,elapsed_time(start_time)/60))\n",
    "\n",
    "        if epoch in show_epoch_list:\n",
    "            print('epoch = {}'.format(epoch))\n",
    "            if not EMA:\n",
    "                show_generate_imgs(netG,fixed_noise,fixed_aux_labels_ohe)\n",
    "            elif EMA:\n",
    "                show_generate_imgs(netG_EMA,fixed_noise,fixed_aux_labels_ohe)\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            if not EMA:\n",
    "                torch.save(netG.state_dict(), f'generator_epoch{epoch}.pth')\n",
    "            elif EMA:\n",
    "                torch.save(netG_EMA.state_dict(), f'generator_epoch{epoch}.pth')\n",
    "        \n",
    "    if not EMA:\n",
    "        torch.save(netG.state_dict(), 'generator.pth')\n",
    "    elif EMA:\n",
    "        torch.save(netG_EMA.state_dict(), 'generator.pth')\n",
    "    torch.save(netD.state_dict(), 'discriminator.pth')\n",
    "\n",
    "    res = {'netG':netG,\n",
    "            'netD':netD,\n",
    "            'nz':nz,\n",
    "            'fixed_noise':fixed_noise,\n",
    "            'fixed_aux_labels_ohe':fixed_aux_labels_ohe,\n",
    "            'D_loss_list':D_loss_list,\n",
    "            'G_loss_list':G_loss_list,\n",
    "            }\n",
    "    if EMA:\n",
    "        res['netG_EMA'] = netG_EMA\n",
    "    \n",
    "    return res"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "%%time \n",
    "show_epoch_list = np.arange(0, 500+10, 10)\n",
    "\n",
    "res = run(lr_G=3e-4,lr_D=3e-4, beta1=0.0, beta2=0.999, nz=120, epochs=500, \n",
    "          n_ite_D=1, ema_decay_rate=None, show_epoch_list=show_epoch_list, output_freq=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10491625\n",
      "8497274\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/xchen/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 23.70 GiB total capacity; 21.62 GiB already allocated; 44.56 MiB free; 22.01 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e2d0e2f8aad9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(lr_G, lr_D, beta1, beta2, nz, epochs, n_ite_D, ema_decay_rate, show_epoch_list, output_freq)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0maux_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_labels_ohe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mdis_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-925e33b1c052>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z, label_ohe, codes_dim)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mcondition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ohe\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (*, 4ch, 32, 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# not change shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-925e33b1c052>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, condition)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3x3_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3x3_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-6278d320c7c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, label)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 144.00 MiB (GPU 0; 23.70 GiB total capacity; 21.62 GiB already allocated; 44.56 MiB free; 22.01 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(res['D_loss_list'], label='D_loss')\n",
    "plt.plot(res['G_loss_list'], label='G_loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title('loss history');"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 372.103125 263.63625\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-08-25T22:21:18.875024</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 263.63625 \nL 372.103125 263.63625 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 239.758125 \nL 364.903125 239.758125 \nL 364.903125 22.318125 \nL 30.103125 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 45.321307 239.758125 \nL 45.321307 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mf2bb06a8a4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(42.140057 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 89.496 239.758125 \nL 89.496 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.496\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 100 -->\n      <g transform=\"translate(79.95225 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 133.670693 239.758125 \nL 133.670693 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"133.670693\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 200 -->\n      <g transform=\"translate(124.126943 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 177.845387 239.758125 \nL 177.845387 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"177.845387\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 300 -->\n      <g transform=\"translate(168.301637 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 222.02008 239.758125 \nL 222.02008 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"222.02008\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 400 -->\n      <g transform=\"translate(212.47633 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 266.194773 239.758125 \nL 266.194773 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"266.194773\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 500 -->\n      <g transform=\"translate(256.651023 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 310.369466 239.758125 \nL 310.369466 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"310.369466\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 600 -->\n      <g transform=\"translate(300.825716 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 354.544159 239.758125 \nL 354.544159 22.318125 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"354.544159\" xlink:href=\"#mf2bb06a8a4\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 700 -->\n      <g transform=\"translate(345.000409 254.356563)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 230.263309 \nL 364.903125 230.263309 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m4380cd4325\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"230.263309\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.0 -->\n      <g transform=\"translate(7.2 234.062528)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 194.454393 \nL 364.903125 194.454393 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"194.454393\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.2 -->\n      <g transform=\"translate(7.2 198.253612)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 158.645477 \nL 364.903125 158.645477 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"158.645477\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.4 -->\n      <g transform=\"translate(7.2 162.444695)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 122.83656 \nL 364.903125 122.83656 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"122.83656\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.6 -->\n      <g transform=\"translate(7.2 126.635779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 87.027644 \nL 364.903125 87.027644 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"87.027644\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.8 -->\n      <g transform=\"translate(7.2 90.826863)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#p2d2712e736)\" d=\"M 30.103125 51.218728 \nL 364.903125 51.218728 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m4380cd4325\" y=\"51.218728\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 55.017947)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#p2d2712e736)\" d=\"M 45.321307 229.874489 \nL 45.763054 227.280675 \nL 46.204801 226.233383 \nL 47.088295 225.431452 \nL 48.855282 224.147837 \nL 50.62227 223.015776 \nL 53.272752 221.306935 \nL 55.923233 219.624875 \nL 57.690221 218.508262 \nL 59.898956 216.895302 \nL 62.991184 214.878063 \nL 72.709617 208.393458 \nL 74.034857 207.468372 \nL 79.335821 203.929768 \nL 83.75329 200.933463 \nL 84.636784 200.148756 \nL 92.146482 195.111622 \nL 93.029976 194.384455 \nL 98.772686 190.603324 \nL 106.72413 185.361354 \nL 108.049371 184.416512 \nL 116.88431 178.795786 \nL 124.835755 173.825901 \nL 130.578465 170.127784 \nL 135.437681 166.999856 \nL 155.316293 154.349907 \nL 160.617256 150.970277 \nL 161.942497 149.954714 \nL 167.24346 146.540685 \nL 169.010448 145.244399 \nL 181.379362 137.740403 \nL 185.796831 134.973179 \nL 189.330807 132.573648 \nL 190.656048 131.585806 \nL 192.864782 130.185671 \nL 194.63177 128.996879 \nL 196.840505 127.628482 \nL 204.791949 122.838901 \nL 248.083149 96.587246 \nL 250.291883 95.172269 \nL 264.869532 86.14893 \nL 265.311279 85.738215 \nL 265.753026 85.495447 \nL 266.194773 84.487778 \nL 268.845255 82.698954 \nL 287.840373 70.892646 \nL 293.141336 67.503155 \nL 301.976274 61.848648 \nL 310.811213 56.291115 \nL 346.150968 34.366846 \nL 349.684943 32.201761 \nL 349.684943 32.201761 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_30\">\n    <path clip-path=\"url(#p2d2712e736)\" d=\"M 45.321307 228.415339 \nL 45.763054 226.570536 \nL 46.204801 226.447966 \nL 46.646548 225.110939 \nL 47.530041 224.368525 \nL 49.297029 223.383826 \nL 49.738776 222.81282 \nL 50.180523 222.048056 \nL 51.064017 221.564578 \nL 61.224196 216.880613 \nL 66.966907 214.505504 \nL 79.335821 209.421444 \nL 83.75329 207.597244 \nL 87.287265 206.150919 \nL 91.704735 204.39412 \nL 92.146482 204.057204 \nL 99.214433 201.266231 \nL 115.559069 194.394801 \nL 125.719248 190.135655 \nL 130.578465 188.149216 \nL 131.020212 187.654458 \nL 138.088163 184.711231 \nL 139.413403 184.098466 \nL 150.457077 179.414303 \nL 153.549305 178.122867 \nL 166.801713 172.58843 \nL 168.568701 171.7163 \nL 177.40364 167.982073 \nL 179.170627 167.184866 \nL 184.913337 164.765001 \nL 188.005566 163.513019 \nL 188.88906 163.053465 \nL 192.423035 161.5546 \nL 195.515264 160.150656 \nL 211.8599 153.087754 \nL 214.068635 151.964402 \nL 243.223932 139.242469 \nL 251.617124 135.588187 \nL 252.500618 135.112621 \nL 263.986038 130.289986 \nL 264.869532 129.834054 \nL 265.311279 129.470906 \nL 265.753026 128.494542 \nL 269.287002 126.935243 \nL 273.262724 125.159535 \nL 277.238446 123.491802 \nL 282.539409 121.117654 \nL 300.651034 113.065413 \nL 301.534528 112.580151 \nL 307.277238 110.07829 \nL 309.927719 108.893077 \nL 321.854886 103.619935 \nL 327.597597 100.961769 \nL 335.990788 97.173227 \nL 336.432535 96.718837 \nL 339.083017 95.58824 \nL 349.684943 90.857689 \nL 349.684943 90.857689 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 239.758125 \nL 30.103125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 239.758125 \nL 364.903125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 239.758125 \nL 364.903125 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 22.318125 \nL 364.903125 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_15\">\n    <!-- loss history -->\n    <g transform=\"translate(163.370625 16.318125)scale(0.12 -0.12)\">\n     <defs>\n      <path d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" id=\"DejaVuSans-6c\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" id=\"DejaVuSans-6f\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" id=\"DejaVuSans-68\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" id=\"DejaVuSans-74\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n      <path d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-6c\"/>\n     <use x=\"27.783203\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"88.964844\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"141.064453\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"193.164062\" xlink:href=\"#DejaVuSans-20\"/>\n     <use x=\"224.951172\" xlink:href=\"#DejaVuSans-68\"/>\n     <use x=\"288.330078\" xlink:href=\"#DejaVuSans-69\"/>\n     <use x=\"316.113281\" xlink:href=\"#DejaVuSans-73\"/>\n     <use x=\"368.212891\" xlink:href=\"#DejaVuSans-74\"/>\n     <use x=\"407.421875\" xlink:href=\"#DejaVuSans-6f\"/>\n     <use x=\"468.603516\" xlink:href=\"#DejaVuSans-72\"/>\n     <use x=\"509.716797\" xlink:href=\"#DejaVuSans-79\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 37.103125 60.230625 \nL 101.167188 60.230625 \nQ 103.167188 60.230625 103.167188 58.230625 \nL 103.167188 29.318125 \nQ 103.167188 27.318125 101.167188 27.318125 \nL 37.103125 27.318125 \nQ 35.103125 27.318125 35.103125 29.318125 \nL 35.103125 58.230625 \nQ 35.103125 60.230625 37.103125 60.230625 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_31\">\n     <path d=\"M 39.103125 35.416562 \nL 59.103125 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_32\"/>\n    <g id=\"text_16\">\n     <!-- D_loss -->\n     <g transform=\"translate(67.103125 38.916562)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-44\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" id=\"DejaVuSans-5f\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"127.001953\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"154.785156\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"215.966797\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"268.066406\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n    <g id=\"line2d_33\">\n     <path d=\"M 39.103125 50.372813 \nL 59.103125 50.372813 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_34\"/>\n    <g id=\"text_17\">\n     <!-- G_loss -->\n     <g transform=\"translate(67.103125 53.872813)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 3809 666 \nL 3809 1919 \nL 2778 1919 \nL 2778 2438 \nL 4434 2438 \nL 4434 434 \nQ 4069 175 3628 42 \nQ 3188 -91 2688 -91 \nQ 1594 -91 976 548 \nQ 359 1188 359 2328 \nQ 359 3472 976 4111 \nQ 1594 4750 2688 4750 \nQ 3144 4750 3555 4637 \nQ 3966 4525 4313 4306 \nL 4313 3634 \nQ 3963 3931 3569 4081 \nQ 3175 4231 2741 4231 \nQ 1884 4231 1454 3753 \nQ 1025 3275 1025 2328 \nQ 1025 1384 1454 906 \nQ 1884 428 2741 428 \nQ 3075 428 3337 486 \nQ 3600 544 3809 666 \nz\n\" id=\"DejaVuSans-47\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-47\"/>\n      <use x=\"77.490234\" xlink:href=\"#DejaVuSans-5f\"/>\n      <use x=\"127.490234\" xlink:href=\"#DejaVuSans-6c\"/>\n      <use x=\"155.273438\" xlink:href=\"#DejaVuSans-6f\"/>\n      <use x=\"216.455078\" xlink:href=\"#DejaVuSans-73\"/>\n      <use x=\"268.554688\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2d2712e736\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "39bb97b9402fe54965182cdecdf1de398681b71a98db533a4cd01c0e11e7c257"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}